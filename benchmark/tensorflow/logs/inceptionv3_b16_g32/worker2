I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
INFO:tensorflow:PS hosts are: ['10.0.0.154:2222', '10.0.1.38:2222', '10.0.1.25:2222', '10.0.1.139:2222']
INFO:tensorflow:Worker hosts are: ['10.0.0.154:2230', '10.0.1.38:2230', '10.0.1.25:2230', '10.0.1.139:2230']
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:17.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2573060
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:18.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2631de0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:19.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2635760
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1a.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x26390e0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 4 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1b.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x263ca60
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 5 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1c.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x26403e0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 6 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1d.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2643d60
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 7 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3 4 5 6 7 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 4:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 5:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 6:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 7:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:17.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:18.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:19.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:1a.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:4) -> (device: 4, name: Tesla K80, pci bus id: 0000:00:1b.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:5) -> (device: 5, name: Tesla K80, pci bus id: 0000:00:1c.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:6) -> (device: 6, name: Tesla K80, pci bus id: 0000:00:1d.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:7) -> (device: 7, name: Tesla K80, pci bus id: 0000:00:1e.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:200] Initialize GrpcChannelCache for job ps -> {0 -> 10.0.0.154:2222, 1 -> 10.0.1.38:2222, 2 -> 10.0.1.25:2222, 3 -> 10.0.1.139:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:200] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.154:2230, 1 -> 10.0.1.38:2230, 2 -> localhost:2230, 3 -> 10.0.1.139:2230}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:219] Started server with target: grpc://localhost:2230
WARNING:tensorflow:From /tmp/inception/inception/inception_model.py:118: concat (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2016-12-14.
Instructions for updating:
This op will be removed after the deprecation date. Please switch to tf.concat_v2().
INFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=4; total_num_replicas=4
WARNING:tensorflow:From /tmp/inception/inception/inception_distributed_train.py:238: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
INFO:tensorflow:2017-01-23 22:30:41.694155 Supervisor
I tensorflow/core/distributed_runtime/master_session.cc:1011] Start master session 4dce1404f898e84a with config: 
allow_soft_placement: true

INFO:tensorflow:Started 0 queues for processing input data.
INFO:tensorflow:Not considering step 0 (0.3 samples/sec)
INFO:tensorflow:Not considering step 0 (15.4 samples/sec)
INFO:tensorflow:Not considering step 1 (8.9 samples/sec)
INFO:tensorflow:Not considering step 2 (9.1 samples/sec)
INFO:tensorflow:Not considering step 3 (10.3 samples/sec)
INFO:tensorflow:Not considering step 4 (5.1 samples/sec)
INFO:tensorflow:Not considering step 5 (17.4 samples/sec)
INFO:tensorflow:Not considering step 6 (17.1 samples/sec)
INFO:tensorflow:Not considering step 7 (17.3 samples/sec)
INFO:tensorflow:Not considering step 8 (4.4 samples/sec)
INFO:tensorflow:Not considering step 9 (15.1 samples/sec)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:15.564385: step 10, loss = 9.08(17.3 examples/sec; 0.927  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:16.482345: step 11, loss = 8.35(17.4 examples/sec; 0.918  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:17.414587: step 12, loss = 9.17(17.2 examples/sec; 0.932  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:18.331664: step 13, loss = 8.85(17.5 examples/sec; 0.917  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:19.269879: step 14, loss = 8.87(17.1 examples/sec; 0.938  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:20.213758: step 15, loss = 9.05(17.0 examples/sec; 0.944  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:21.130734: step 16, loss = 9.28(17.5 examples/sec; 0.917  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:22.065056: step 17, loss = 9.47(17.1 examples/sec; 0.934  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:23.009030: step 18, loss = 9.56(17.0 examples/sec; 0.944  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:23.961379: step 19, loss = 9.16(16.8 examples/sec; 0.952  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:24.904888: step 20, loss = 8.35(17.0 examples/sec; 0.943  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:25.833524: step 21, loss = 8.43(17.2 examples/sec; 0.928  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:26.769278: step 22, loss = 7.47(17.1 examples/sec; 0.936  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:27.704914: step 23, loss = 7.67(17.1 examples/sec; 0.935  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:28.639047: step 24, loss = 7.51(17.1 examples/sec; 0.934  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:29.580196: step 25, loss = 7.38(17.0 examples/sec; 0.941  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:30.500791: step 26, loss = 6.99(17.4 examples/sec; 0.920  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:31.427715: step 27, loss = 6.82(17.3 examples/sec; 0.927  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:32.356324: step 28, loss = 6.82(17.2 examples/sec; 0.928  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:33.306834: step 29, loss = 6.41(16.8 examples/sec; 0.950  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:34.229303: step 30, loss = 6.11(17.3 examples/sec; 0.922  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:35.167840: step 31, loss = 6.10(17.1 examples/sec; 0.938  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:36.096562: step 32, loss = 6.06(17.2 examples/sec; 0.929  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:37.025237: step 33, loss = 6.02(17.2 examples/sec; 0.928  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:37.952520: step 34, loss = 5.93(17.3 examples/sec; 0.927  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:38.880509: step 35, loss = 5.66(17.2 examples/sec; 0.928  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:39.804652: step 36, loss = 5.50(17.3 examples/sec; 0.924  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:40.736941: step 37, loss = 5.40(17.2 examples/sec; 0.932  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:41.677979: step 38, loss = 5.39(17.0 examples/sec; 0.941  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:42.605975: step 39, loss = 5.41(17.2 examples/sec; 0.928  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:43.558463: step 40, loss = 5.41(16.8 examples/sec; 0.952  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:44.508637: step 41, loss = 5.36(16.8 examples/sec; 0.950  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:45.443283: step 42, loss = 5.26(17.1 examples/sec; 0.934  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:46.398014: step 43, loss = 5.18(16.8 examples/sec; 0.955  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:47.342584: step 44, loss = 5.11(16.9 examples/sec; 0.944  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:48.280418: step 45, loss = 5.07(17.1 examples/sec; 0.938  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:49.232200: step 46, loss = 5.05(16.8 examples/sec; 0.952  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:50.176449: step 47, loss = 5.05(16.9 examples/sec; 0.944  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:51.116741: step 48, loss = 5.03(17.0 examples/sec; 0.940  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:52.043916: step 49, loss = 4.99(17.3 examples/sec; 0.927  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:52.994356: step 50, loss = 4.98(16.8 examples/sec; 0.950  sec/batch)
INFO:tensorflow:Worker 2: 2017-01-23 22:32:53.926958: step 51, loss = 4.96(17.2 examples/sec; 0.932  sec/batch)
Traceback (most recent call last):
  File "imagenet_distributed_train.py", line 65, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "imagenet_distributed_train.py", line 61, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File "/tmp/inception/inception/inception_distributed_train.py", line 280, in train
    loss_value, step = sess.run([train_op, global_step])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 767, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 965, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1015, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnavailableError: {"created":"@1485210774.687229380","description":"EOF","file":"external/grpc/src/core/lib/iomgr/tcp_posix.c","file_line":235,"grpc_status":14}
